{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6xFw9ByuzBv14FfXa6HXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alec-carawan/Intro-to-Machine-Learning/blob/main/HW5_Q2_%26_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "8cYthBxAgpfZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housingSet   =   pd.read_csv('https://raw.githubusercontent.com/alec-carawan/datasets/main/Housing.csv')"
      ],
      "metadata": {
        "id": "0TwCsdf0h4yS"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of variables to map\n",
        "\n",
        "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "\n",
        "# Defining the map function\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Applying the function to the housing list\n",
        "housingSet[varlist] = housingSet[varlist].apply(binary_map)\n",
        "\n",
        "#map furnishing status\n",
        "housingSet['furnishingstatus'] = housingSet['furnishingstatus'].map({'furnished': 2, 'semi-furnished': 1, 'unfurnished': 0})"
      ],
      "metadata": {
        "id": "bU02VH5Mh9QL"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STANDARDIZE DATA\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "num_vars = ['price','area','bedrooms','bathrooms','stories','mainroad','guestroom','basement','hotwaterheating','airconditioning','parking','prefarea','furnishingstatus']\n",
        "#using num_vars keeps data types as data frames, instead of np arrays\n",
        "\n",
        "housingSet[num_vars] = scaler.fit_transform(housingSet[num_vars])"
      ],
      "metadata": {
        "id": "y22MxSq0i9bG"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['area','bedrooms','bathrooms','stories','parking']\n",
        "# Separating out the features\n",
        "X = housingSet.loc[:, features].values\n",
        "# Separating out the target\n",
        "y = housingSet.loc[:,['price']].values"
      ],
      "metadata": {
        "id": "_hRdSdWEjdrX"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, )"
      ],
      "metadata": {
        "id": "ES6mx4U4i8va"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear model:\n",
        "\n",
        "w1 * area + w2 * bedrooms + w3 * bathrooms + w4 * stories + w5 * parking + b"
      ],
      "metadata": {
        "id": "AnmDoLn-nZ7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(area, bedrooms, bathrooms, stories, parking, w1, w2, w3, w4, w5, b):\n",
        "    return w1 * area + w2 * bedrooms + w3 * bathrooms + w4 * stories + w5 * parking + b"
      ],
      "metadata": {
        "id": "NZl34s8Rnq7-"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(pred, targ):\n",
        "    squared_diffs = (pred - targ)**2\n",
        "    return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "9UZE0PmsoRdl"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "area_t       = torch.tensor(X_train[:, 0])\n",
        "bedrooms_t   = torch.tensor(X_train[:, 1])\n",
        "bathrooms_t  = torch.tensor(X_train[:, 2])\n",
        "stories_t    = torch.tensor(X_train[:, 3])\n",
        "parking_t    = torch.tensor(X_train[:, 4])\n",
        "price_t      = torch.tensor(y_train[:, :])\n",
        "\n",
        "area_v       = torch.tensor(X_test[:, 0])\n",
        "bedrooms_v   = torch.tensor(X_test[:, 1])\n",
        "bathrooms_v  = torch.tensor(X_test[:, 2])\n",
        "stories_v    = torch.tensor(X_test[:, 3])\n",
        "parking_v    = torch.tensor(X_test[:, 4])\n",
        "price_v      = torch.tensor(y_test[:, :])"
      ],
      "metadata": {
        "id": "MJfJ3dvQpjCH"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(area_t, bedrooms_t, bathrooms_t, stories_t, parking_t, *params)\n",
        "loss = loss_fn(pred, price_t)\n",
        "loss.backward()\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDLfiexgshz7",
        "outputId": "73815b57-fea8-4d44-bd23-93ae81bf8100"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.9999e-01,  9.9999e-01,  1.0000e+00,  9.9999e-01,  9.9999e-01,\n",
              "        -1.9027e-05], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params,\n",
        "                  area_t, bedrooms_t, bathrooms_t, stories_t, parking_t, price_t,\n",
        "                  area_v, bedrooms_v, bathrooms_v, stories_v, parking_v, price_v):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_pred = model(area_t, bedrooms_t, bathrooms_t, stories_t, parking_t, *params)\n",
        "        train_loss = loss_fn(train_pred, price_t)\n",
        "\n",
        "        val_pred = model(area_v, bedrooms_v, bathrooms_v, stories_v, parking_v, *params)\n",
        "        val_loss = loss_fn(val_pred, price_v)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward() # <2>\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch <= 3 or epoch % 500 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "                  f\" Validation loss {val_loss.item():.4f}\")\n",
        "\n",
        "    return params\n"
      ],
      "metadata": {
        "id": "8xfQOr_NrrU0"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000, optimizer = optimizer, params = params,\n",
        "    area_t = area_t, bedrooms_t = bedrooms_t, bathrooms_t = bathrooms_t, stories_t = stories_t, parking_t = parking_t, price_t = price_t,\n",
        "    area_v = area_v, bedrooms_v = bedrooms_v, bathrooms_v = bathrooms_v, stories_v = stories_v, parking_v = parking_v, price_v = price_v\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACObmt9cypb9",
        "outputId": "094e07a3-b7b1-4df5-cf87-4b8e5a556c4a"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 1.3349, Validation loss 1.5305\n",
            "Epoch 2, Training loss 1.2785, Validation loss 1.4676\n",
            "Epoch 3, Training loss 1.2251, Validation loss 1.4080\n",
            "Epoch 500, Training loss 0.0931, Validation loss 0.0947\n",
            "Epoch 1000, Training loss 0.0467, Validation loss 0.0480\n",
            "Epoch 1500, Training loss 0.0345, Validation loss 0.0369\n",
            "Epoch 2000, Training loss 0.0304, Validation loss 0.0334\n",
            "Epoch 2500, Training loss 0.0286, Validation loss 0.0318\n",
            "Epoch 3000, Training loss 0.0275, Validation loss 0.0308\n",
            "Epoch 3500, Training loss 0.0269, Validation loss 0.0302\n",
            "Epoch 4000, Training loss 0.0264, Validation loss 0.0298\n",
            "Epoch 4500, Training loss 0.0262, Validation loss 0.0295\n",
            "Epoch 5000, Training loss 0.0260, Validation loss 0.0293\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0937,  0.1092, -0.0026, -0.0290, -0.0317,  0.2045],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000, optimizer = optimizer, params = params,\n",
        "    area_t = area_t, bedrooms_t = bedrooms_t, bathrooms_t = bathrooms_t, stories_t = stories_t, parking_t = parking_t, price_t = price_t,\n",
        "    area_v = area_v, bedrooms_v = bedrooms_v, bathrooms_v = bathrooms_v, stories_v = stories_v, parking_v = parking_v, price_v = price_v\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsR7QtYu2o53",
        "outputId": "f6f59027-406c-464d-e39d-94790f1da849"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 1.3349, Validation loss 1.5305\n",
            "Epoch 2, Training loss 1.2853, Validation loss 1.4745\n",
            "Epoch 3, Training loss 1.2369, Validation loss 1.4197\n",
            "Epoch 500, Training loss 0.0290, Validation loss 0.0322\n",
            "Epoch 1000, Training loss 0.0258, Validation loss 0.0291\n",
            "Epoch 1500, Training loss 0.0256, Validation loss 0.0288\n",
            "Epoch 2000, Training loss 0.0256, Validation loss 0.0288\n",
            "Epoch 2500, Training loss 0.0256, Validation loss 0.0288\n",
            "Epoch 3000, Training loss 0.0256, Validation loss 0.0288\n",
            "Epoch 3500, Training loss 0.0256, Validation loss 0.0288\n",
            "Epoch 4000, Training loss 0.0256, Validation loss 0.0288\n",
            "Epoch 4500, Training loss 0.0256, Validation loss 0.0288\n",
            "Epoch 5000, Training loss 0.0256, Validation loss 0.0288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.7383e-08,  2.3006e-07, -4.8021e-08,  3.1744e-11,  3.2183e-09,\n",
              "         2.5553e-01], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['area','bedrooms','bathrooms','stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']\n",
        "# Separating out the features\n",
        "X = housingSet.loc[:, features].values\n",
        "# Separating out the target\n",
        "y = housingSet.loc[:,['price']].values"
      ],
      "metadata": {
        "id": "pogJb6VJa997"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, )"
      ],
      "metadata": {
        "id": "gr0LWkA-bkFB"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(area, bedrooms, bathrooms, stories, mainroad, guestroom, basement, hotwaterheating, airconditioning, parking, prefarea, furnishingstatus, w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, w11, w12, b):\n",
        "    return w1 * area + w2 * bedrooms + w3 * bathrooms + w4 * stories + w5 * mainroad + w6 * guestroom + w7 * basement + w8 * hotwaterheating + w9 * airconditioning + w10 * parking + w11 * prefarea + w12 * furnishingstatus + b"
      ],
      "metadata": {
        "id": "_Iafxm37eVVD"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "area_t                = torch.tensor(X_train[:, 0])\n",
        "bedrooms_t            = torch.tensor(X_train[:, 1])\n",
        "bathrooms_t           = torch.tensor(X_train[:, 2])\n",
        "stories_t             = torch.tensor(X_train[:, 3])\n",
        "mainroad_t            = torch.tensor(X_train[:, 4])\n",
        "guestroom_t           = torch.tensor(X_train[:, 5])\n",
        "basement_t            = torch.tensor(X_train[:, 6])\n",
        "hotwaterheating_t     = torch.tensor(X_train[:, 7])\n",
        "airconditioning_t     = torch.tensor(X_train[:, 8])\n",
        "parking_t             = torch.tensor(X_train[:, 9])\n",
        "prefarea_t            = torch.tensor(X_train[:, 10])\n",
        "furnishingstatus_t    = torch.tensor(X_train[:, 11])\n",
        "price_t               = torch.tensor(y_train[:, :])\n",
        "\n",
        "area_v                = torch.tensor(X_test[:, 0])\n",
        "bedrooms_v            = torch.tensor(X_test[:, 1])\n",
        "bathrooms_v           = torch.tensor(X_test[:, 2])\n",
        "stories_v             = torch.tensor(X_test[:, 3])\n",
        "mainroad_v            = torch.tensor(X_test[:, 4])\n",
        "guestroom_v           = torch.tensor(X_test[:, 5])\n",
        "basement_v            = torch.tensor(X_test[:, 6])\n",
        "hotwaterheating_v     = torch.tensor(X_test[:, 7])\n",
        "airconditioning_v     = torch.tensor(X_test[:, 8])\n",
        "parking_v             = torch.tensor(X_test[:, 9])\n",
        "prefarea_v            = torch.tensor(X_test[:, 10])\n",
        "furnishingstatus_v    = torch.tensor(X_test[:, 11])\n",
        "price_v               = torch.tensor(y_test[:, :])"
      ],
      "metadata": {
        "id": "ozqc0y_-gIWC"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(area_t, bedrooms_t, bathrooms_t, stories_t, mainroad_t, guestroom_t, basement_t, hotwaterheating_t, airconditioning_t, parking_t, prefarea_t, furnishingstatus_t, *params)\n",
        "loss = loss_fn(pred, price_t)\n",
        "loss.backward()\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txzHEvHOm-Ry",
        "outputId": "87aa1a7a-a737-482b-dd70-586bcabfd12b"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.9982e-01,  9.9972e-01,  9.9991e-01,  9.9979e-01,  9.9937e-01,\n",
              "         9.9982e-01,  9.9969e-01,  9.9996e-01,  9.9971e-01,  9.9980e-01,\n",
              "         9.9977e-01,  9.9963e-01, -6.7955e-04], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params,\n",
        "                  area_t, bedrooms_t, bathrooms_t, stories_t, mainroad_t, guestroom_t, basement_t, hotwaterheating_t, airconditioning_t, parking_t, prefarea_t, furnishingstatus_t, price_t,\n",
        "                  area_v, bedrooms_v, bathrooms_v, stories_v, mainroad_v, guestroom_v, basement_v, hotwaterheating_v, airconditioning_v, parking_v, prefarea_v, furnishingstatus_v, price_v):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_pred = model(area_t, bedrooms_t, bathrooms_t, stories_t, mainroad_t, guestroom_t, basement_t, hotwaterheating_t, airconditioning_t, parking_t, prefarea_t, furnishingstatus_t, *params)\n",
        "        train_loss = loss_fn(train_pred, price_t)\n",
        "\n",
        "        val_pred = model(area_v, bedrooms_v, bathrooms_v, stories_v, mainroad_v, guestroom_v, basement_v, hotwaterheating_v, airconditioning_v, parking_v, prefarea_v, furnishingstatus_v, *params)\n",
        "        val_loss = loss_fn(val_pred, price_v)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward() # <2>\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch <= 3 or epoch % 500 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "                  f\" Validation loss {val_loss.item():.4f}\")\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "VBRTPKbbn0Jn"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000, optimizer = optimizer, params = params,\n",
        "    area_t = area_t, bedrooms_t = bedrooms_t, bathrooms_t = bathrooms_t, stories_t = stories_t, mainroad_t = mainroad_t, guestroom_t = guestroom_t, basement_t = basement_t, hotwaterheating_t = hotwaterheating_t, airconditioning_t = airconditioning_t, parking_t = parking_t, prefarea_t = prefarea_t, furnishingstatus_t = furnishingstatus_t, price_t = price_t,\n",
        "    area_v = area_v, bedrooms_v = bedrooms_v, bathrooms_v = bathrooms_v, stories_v = stories_v, mainroad_v = mainroad_v, guestroom_v = guestroom_v, basement_v = basement_v, hotwaterheating_v = hotwaterheating_v, airconditioning_v = airconditioning_v, parking_v = parking_v, prefarea_v = prefarea_v, furnishingstatus_v = furnishingstatus_v, price_v = price_v\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnLZSVxgrkMN",
        "outputId": "5bc457c9-da4a-4d64-c1db-b15ffb97c9ab"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 14.1932, Validation loss 15.5565\n",
            "Epoch 2, Training loss 12.7619, Validation loss 14.0363\n",
            "Epoch 3, Training loss 11.4825, Validation loss 12.6753\n",
            "Epoch 500, Training loss 0.1098, Validation loss 0.1343\n",
            "Epoch 1000, Training loss 0.0533, Validation loss 0.0633\n",
            "Epoch 1500, Training loss 0.0377, Validation loss 0.0434\n",
            "Epoch 2000, Training loss 0.0317, Validation loss 0.0362\n",
            "Epoch 2500, Training loss 0.0290, Validation loss 0.0331\n",
            "Epoch 3000, Training loss 0.0277, Validation loss 0.0316\n",
            "Epoch 3500, Training loss 0.0269, Validation loss 0.0308\n",
            "Epoch 4000, Training loss 0.0264, Validation loss 0.0304\n",
            "Epoch 4500, Training loss 0.0261, Validation loss 0.0301\n",
            "Epoch 5000, Training loss 0.0258, Validation loss 0.0299\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0988,  0.1188, -0.0031, -0.0325,  0.0098, -0.0005, -0.0043,  0.0145,\n",
              "        -0.0020, -0.0306, -0.0063, -0.0005,  0.2013], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000, optimizer = optimizer, params = params,\n",
        "    area_t = area_t, bedrooms_t = bedrooms_t, bathrooms_t = bathrooms_t, stories_t = stories_t, mainroad_t = mainroad_t, guestroom_t = guestroom_t, basement_t = basement_t, hotwaterheating_t = hotwaterheating_t, airconditioning_t = airconditioning_t, parking_t = parking_t, prefarea_t = prefarea_t, furnishingstatus_t = furnishingstatus_t, price_t = price_t,\n",
        "    area_v = area_v, bedrooms_v = bedrooms_v, bathrooms_v = bathrooms_v, stories_v = stories_v, mainroad_v = mainroad_v, guestroom_v = guestroom_v, basement_v = basement_v, hotwaterheating_v = hotwaterheating_v, airconditioning_v = airconditioning_v, parking_v = parking_v, prefarea_v = prefarea_v, furnishingstatus_v = furnishingstatus_v, price_v = price_v\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQSFyibS25SN",
        "outputId": "06f64405-f9c4-4fab-cdaa-9d3d9819020f"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 14.1932, Validation loss 15.5565\n",
            "Epoch 2, Training loss 10.7463, Validation loss 11.8286\n",
            "Epoch 3, Training loss 7.8025, Validation loss 8.6376\n",
            "Epoch 500, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 1000, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 1500, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 2000, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 2500, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 3000, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 3500, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 4000, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 4500, Training loss 0.0254, Validation loss 0.0294\n",
            "Epoch 5000, Training loss 0.0254, Validation loss 0.0294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0025e-08,  4.3838e-08, -8.9852e-09, -2.3951e-09,  1.5930e-08,\n",
              "        -3.0055e-10,  2.0372e-09,  1.1295e-09,  2.8229e-10, -2.1855e-09,\n",
              "        -1.9814e-09,  3.7969e-09,  2.6057e-01], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    }
  ]
}